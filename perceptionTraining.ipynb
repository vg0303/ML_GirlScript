{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perceptionTraining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyrI70kU4G3+wS8MHSQzT4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vg0303/ML_GirlScript/blob/main/perceptionTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6scO0NDl4U_"
      },
      "source": [
        "Date created: 10/06/21\n",
        "\n",
        "By: Vrinda Gupta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlr56_Ysmf0V"
      },
      "source": [
        "#Problem Statement:\n",
        "Tarin a model to learn the table of 10\n",
        "\n",
        "equation: `y=10*x`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oImkvjcunuOC"
      },
      "source": [
        "#Data Creation\n",
        "\n",
        "equation: `y= 10*x`\n",
        "\n",
        "x= [1, 2, 3, 4, 5, .....]    (input)\n",
        "\n",
        "y= [10, 20, 30, 40, 50, .....]     (labels)\n",
        "\n",
        "Some percent of the data is used for training and rest for testing the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ble7ms_toXB3",
        "outputId": "2373007f-dd43-4a1a-95fa-0ce4c4a0bdb9"
      },
      "source": [
        "x= [i for i in range(21)]\n",
        "print (x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA5VjhA1ppaa",
        "outputId": "7b2948ff-593b-42d2-ebbe-7bac6b722998"
      },
      "source": [
        "y= [i for i in range(10*20+1) if i%10 == 0]\n",
        "print (y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuFK2Dekq4Km"
      },
      "source": [
        "#Approach 1\n",
        "\n",
        "without using ML, using normal functions for equation `y=10*x`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok3xGlovrDkg",
        "outputId": "cdc4a486-fcd9-4ec9-b8c8-88c5a781bb73"
      },
      "source": [
        "def tableOf10 (x):\n",
        "  y=10*x\n",
        "  return y\n",
        "\n",
        "for val in x:\n",
        "  print (tableOf10(val) )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCFY_FV3sM7a"
      },
      "source": [
        "#Approach 2\n",
        "\n",
        "Now we will try out the ML model for this problem which will be a redundant ML model, for this we will need to split the data into training data and testing data\n",
        "\n",
        "you are going to need `xTrain` and `yTrain`, `xTest` and `yTest` from the `x` and `y` list\n",
        "\n",
        "where `xTrain` and `yTrain` are for dataset for training purpose\n",
        "\n",
        "and `xTest` and `yTest` are for testing purpose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYs7dOumB0mf",
        "outputId": "3bb67369-219f-492f-ca0c-50eb1b9dfa06"
      },
      "source": [
        "print (f'this is x: {x}')\n",
        "print (f'this is y: {y}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is x: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "this is y: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKEpa6A9s4eK",
        "outputId": "e0b3196c-0027-4058-bb28-e933e001f4ce"
      },
      "source": [
        "xTrain= x[:-5]   #training data \n",
        "yTrain= y[:-5]   #training labels\n",
        "\n",
        "xTest= x[-5:]    #testing data\n",
        "yTest= y[-5:]    #testing lables\n",
        "\n",
        "print(f'''\n",
        "xTrain: {xTrain}\n",
        "yTrain: {yTrain}\n",
        "\n",
        "xTest: {xTest}\n",
        "yTest: {yTest}\n",
        "''')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "xTrain: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "yTrain: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
            "\n",
            "xTest: [16, 17, 18, 19, 20]\n",
            "yTest: [160, 170, 180, 190, 200]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s39fYFEqFwoY"
      },
      "source": [
        "We will be using TensorFlow which is a framework and Keras for building the ML model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_DQ_xQfF8_g"
      },
      "source": [
        "#importing the necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTzWD4ArGY-w"
      },
      "source": [
        "#perception model\n",
        "model= tf.keras.Sequential([\n",
        "                            tf.keras.layers.Dense( units=1, input_shape= [1])   \n",
        "])\n",
        "#dense=> completely conected network, \n",
        "#units=> no. of neurons, \n",
        "#input_shape=> in what pattern data is inputed, in this eg one int at a time"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oH4uxKUPSpw"
      },
      "source": [
        "We have defined the model, now we need to compile it to reduce the error* during the training phase.\n",
        "\n",
        "We use the adam optimizer\n",
        "\n",
        "Since this is a regression problem (how do we know it is regression? look at the equation above y = 10x) we are going to use `mean absolute error` \"mae\" but you can try `mean squared error` \"mse\" as well\n",
        "\n",
        "*error is the difference between the predicted label (output of ML model) and the actual label (label you have)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku2GcfdGNDPR"
      },
      "source": [
        "#MAE (mean absolute error)\n",
        "\n",
        "the prediction of the model based on the input val xTrain: `h(xTrains) = [...]`\n",
        "\n",
        "`yTrains = [...]`\n",
        "\n",
        "n = length of yTrain\n",
        "\n",
        "> **mae = | (xTrain_i - h(xTrain_i)) | / n**    \n",
        "\n",
        "(`loss` in the below data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di1Jng3bJLnZ"
      },
      "source": [
        "model.compile(optimizer='adam', loss='mae')  #mae = Mean Absolute Error, we can also use mse"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhL-MXhRKIcU",
        "outputId": "06411063-311e-4074-cc07-563d230cee48"
      },
      "source": [
        "#training the data for 50 times\n",
        "model.fit(x=xTrain, y=yTrain, validation_data=(xTest, yTest), epochs=50) #for training the model fit(); epochs= no of time the model trains"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 3s 3s/step - loss: 67.1304 - val_loss: 161.0941\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 67.1221 - val_loss: 161.0751\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 67.1137 - val_loss: 161.0561\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 67.1053 - val_loss: 161.0371\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 67.0970 - val_loss: 161.0181\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 67.0886 - val_loss: 160.9991\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 67.0802 - val_loss: 160.9801\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 67.0718 - val_loss: 160.9611\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 67.0635 - val_loss: 160.9421\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 67.0551 - val_loss: 160.9231\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 67.0467 - val_loss: 160.9041\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 67.0384 - val_loss: 160.8851\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 67.0300 - val_loss: 160.8661\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 67.0216 - val_loss: 160.8471\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 67.0132 - val_loss: 160.8281\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 67.0049 - val_loss: 160.8091\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 66.9965 - val_loss: 160.7901\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 66.9881 - val_loss: 160.7711\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 66.9797 - val_loss: 160.7521\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 66.9714 - val_loss: 160.7331\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 66.9630 - val_loss: 160.7141\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 66.9546 - val_loss: 160.6951\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 66.9462 - val_loss: 160.6761\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 66.9379 - val_loss: 160.6571\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 66.9295 - val_loss: 160.6381\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 66.9211 - val_loss: 160.6191\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 66.9128 - val_loss: 160.6001\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 66.9044 - val_loss: 160.5811\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 66.8960 - val_loss: 160.5621\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 66.8876 - val_loss: 160.5431\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 66.8793 - val_loss: 160.5241\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 66.8709 - val_loss: 160.5051\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 66.8625 - val_loss: 160.4861\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 66.8541 - val_loss: 160.4671\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 66.8458 - val_loss: 160.4482\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 66.8374 - val_loss: 160.4292\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 66.8290 - val_loss: 160.4101\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 66.8206 - val_loss: 160.3911\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 66.8123 - val_loss: 160.3722\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 66.8039 - val_loss: 160.3531\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 66.7955 - val_loss: 160.3342\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 66.7871 - val_loss: 160.3151\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 66.7788 - val_loss: 160.2961\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 66.7704 - val_loss: 160.2771\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 66.7620 - val_loss: 160.2581\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 66.7537 - val_loss: 160.2392\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 66.7453 - val_loss: 160.2202\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 66.7369 - val_loss: 160.2012\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 66.7285 - val_loss: 160.1822\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 66.7202 - val_loss: 160.1632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f81b00da490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVUqEn-qRnVo"
      },
      "source": [
        "**val_loss** denotes how far could your models prediction be from the actual label i.e the cost function, J(x).\n",
        "\n",
        "So let's say if you give the input x = 10 to your model you are expecting the ideal output to be 100, why? Because y = 10*x = 10x10 = 100.\n",
        "\n",
        "Now you would get 100 if you're not using Machine Learning. If you use the Approach 1 (that works on Crisp / Boolean Logic) you would get an exact 100, but if you use machine learning (that uses fuzzy logic) you would get the value close to 100 but never exactly 100.\n",
        "\n",
        " **In the current scenario it would be 10*x ± val_loss = 10x10 ± 160.1632**\n",
        "\n",
        "Because the validation loss is 160.1632, and our intention is to reduce the loss and bring it down as closer to zero as much as we can."
      ]
    }
  ]
}